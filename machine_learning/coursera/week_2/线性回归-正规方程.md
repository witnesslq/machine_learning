## 1. 正规方程
前面几篇文章里面我们介绍了求解线性回归模型第一个算法`梯度下降算法`，梯度下降算法最核心的是找到一个学习速率α，通过不断的迭代最终找到θ0 ... θn, 使得J(θ)值最小。

今天我们要介绍一个解决线性回归模型新的算法`正规方程` 对于函数f(x) = ax^2 + bx + c 而言，要求其最小值，是对其求导数并且设置导数值为0. 

我们知道，多维特征变量的线性回归模型中，代价函数表达式，如下图所示

![](https://camo.githubusercontent.com/69d7473a15e3ebc5f447bdf7d3091cc2eb0a4f8e/687474703a2f2f696d672e626c6f672e6373646e2e6e65742f3230313630343138313931333030333836)

扩展到n个参数θ0 ... θn，求函数J(θ)也可以对每个参数求导并另导数为0

![](http://52opencourse.com/?qa=blob&qa_blobid=15879228446089531536)

经数学证明，运用线性代数的公式，可以直接求解特征向量θ（θ0,θ1 ... θn）使得代价函数J（θ）最小

![](http://img.blog.csdn.net/20151007151320124?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

1. X表示特征向量矩阵
2. X^T表示的是矩阵X的转置矩阵
3. (X^T*X)^-1，表示矩阵X转置矩阵和它相乘得到的新矩阵求逆
4. Y表示训练集中，结果矩阵

## 2. 举例说明
假设我们预测房价的训练集如下所示

![](http://52opencourse.com/?qa=blob&qa_blobid=13686817329013927315)

![](http://52opencourse.com/?qa=blob&qa_blobid=10192551476322867713)

![](http://52opencourse.com/?qa=blob&qa_blobid=3391957727547829744)

训练集m=4，特征维度n=4，同时我们假设X0=1，因此特征矩阵X=m*(n+1)

证明如下

1. X = m*(n+1)
2. X^T = (n+1)*m
3. (X^T * X) = (n+1) * (n+1)
4. (X^T * X)^-1 = (n+1) * (n+1)
5. Y = m * 1
5. X^T * Y = (n+1) * 1
6. (X^T * X)^-1 * X^T * Y = ((n+1) * (n+1)) * ((n+1) * 1) = (n+1) * 1

由上可知，求出的向量即为θ（θ0,θ1 ... θn）

`特别注意: 并不是所有(X^T * X)相乘的结果都可逆，不过我们一般不用太关心这些细节，对于MATLAB或者octave来说都可以无论可逆不可逆，最终都可以求出结果`

## 3. 什么时候选择正规方程
梯度下降特点:

1. 选择合适的学习速率α
2. 通过不断的迭代，找到θ0 ... θn, 使得J(θ)值最小

正规方程特点:

1. 不需要选择学习速率α，不需要n轮迭代
2. 只需要一个公式计算即可

但是并不是所有的线性回归都适合用正规方程，我们知道求解一个矩阵的逆复杂度位O(n^3)，因此当特征维度n非常大的时候(X^T * X)^-1需要O(n^3)时间。

当n < 1000时候选择正规方程比较合适，但是当n > 1000的时候使用梯度下降算法会是更佳的方案
