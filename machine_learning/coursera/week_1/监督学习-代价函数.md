## 1.引言
当我们的训练集如下图1所示，可以假设hypothesis函数如图2

![](https://camo.githubusercontent.com/f5198c4c49fed874a5c471187c9327c4281527b2/687474703a2f2f696d616765732e636e6974626c6f672e636f6d2f626c6f672f3339323232382f3230313431302f3239313931393431303635353830352e6a7067)

![](http://studentdeng.github.io/images/ml/1.png)

θ0和θ1我们称为hθ(x)函数的2个参数，h是x的函数，所以有时候也记着h(x)

对于这个已有的hypothesis，我们需要什么方法来评估这个假设函数的好坏呢？

因此我们定义了一个叫"代价函数"cost function 来评估当前hθ(x)函数

## 2. 代价函数
cost function也叫作loss function，就是对hθ(x)函数进行评估的一个函数。

`代价函数最重要的作用就是是用来度量预测错误的程度，通常来说，模型越准确，越接近真实，其cost function的值就越小。`

cost function 通常用大写字母J表示，由于cost function的大小和hθ(x)的参数取值相关，不难想象，J是θ的函数，用Jθ表示。

线性回归中的cost function，通常用最小"平方差"来表示，也称为square loss，定义函数如下所以

![](https://camo.githubusercontent.com/9b486198032d4371e83f37c39d0dbec6e12013dd/687474703a2f2f73747564656e7464656e672e6769746875622e696f2f696d616765732f6d6c2f31322e706e67)


这里x和y的右上角标i，表示training set中第i个数据的特征向量和实际值，加括号表示是第i个，而不是i次幂

由cost function定义可以知道，当hθ(x)对training set测试结果完全正确的时候，const function的值是0

因此我们的目标，就是尽量优化hθ(x)，不断更改参数θ0 ~ θn 的值，使得Jθ的值最小，即上图中的Goal

## 3. 举例
为了简化模型，我们假设hθ(x)只有2个参数θ0和θ1，同时假设θ0 = 0

因此hθ(x) = θ1X

我们根据θ1的值等于 -1,0,1,2 可以画出cost function J(θ)的函数图像如下所示。可以发现代价函数J(θ)是一个"凸函数"，存在全局最小值。

![](http://7xn47m.com1.z0.glb.clouddn.com/cost_function.jpg)

不难发现，当θ1 =1 的时候training set能够和hθ(x) 完美拟合成一条直线，此时J(θ)值最小为0

类似的，当θ0不等于0的时候，此时hθ(x)有2个不为0的参数θ0和θ1，J(θ)的图像可能如下图所示

![](http://7xn47m.com1.z0.glb.clouddn.com/cf.jpg)
